{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split  <span style=\"color:red\"> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, lets import pandas so we can handle tables effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:35.144800Z",
     "start_time": "2018-10-17T09:31:35.142179Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Golfer John likes to play golf, but only in certain conditions.  Below is a table of data relating to the different conditions in which Golfer John did and did not play golf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:35.544724Z",
     "start_time": "2018-10-17T09:31:35.537116Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('GolferJohn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the top five rows of this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:35.920621Z",
     "start_time": "2018-10-17T09:31:35.908883Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the table above into X data (features) and y data (in our case, whether or not Golfer John played golf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:36.335773Z",
     "start_time": "2018-10-17T09:31:36.324302Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data[['Weather', 'Temperature', 'Humidity', 'Windy', 'Ice cream available']]        ## Features:  Information relating to whether Golfer John played or not\n",
    "y = data[['Play golf?']]                                                                ## Target:  Whether or not Golfer John played golf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the train_test_split function from the appropriate package:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:36.850603Z",
     "start_time": "2018-10-17T09:31:36.847955Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the train_test_split function, split your data into X_train, X_test, y_train and y_test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:37.499155Z",
     "start_time": "2018-10-17T09:31:37.488117Z"
    }
   },
   "outputs": [],
   "source": [
    "## Put your code in this cell to split the data into the appropriate training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing the same train-test split but this time specifying that the test data is 30% of the total data available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:38.357012Z",
     "start_time": "2018-10-17T09:31:38.352098Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing another train-test split, but this time specifying that the data is shuffled before being split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the benefit of using the 'random_state' parameter?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:32:01.171176Z",
     "start_time": "2018-10-18T15:32:01.070687Z"
    }
   },
   "source": [
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTENSION TASK:**  What does the train-test split's 'stratify' condition do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, we can now use this information to develop a Machine Learning model to predict whether or not Golfer John played in certain weather conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier <span style=\"color:red\"> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below data is for passengers on the Titanic.  We can use Machine Learning to train a model and predict whether a passenger would have survived or not on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T17:08:04.643542Z",
     "start_time": "2018-10-12T17:08:04.639193Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://titanichistoricalsociety.org/wp-content/uploads/2017/09/titanic_historical_society_homepage_harley_crossley.jpg\", width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data below is a subset of the full data available on Kaggle:  https://www.kaggle.com/c/titanic#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:20:02.592415Z",
     "start_time": "2018-10-17T10:20:02.546753Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_data.csv')\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T16:17:37.660183Z",
     "start_time": "2018-09-17T16:17:37.656990Z"
    }
   },
   "source": [
    "Below is a brief description of each of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Feature** |  **Description**   |\n",
    "|:-----------|------------:|\n",
    "| **Survived**       |        This tells us whether the person survived or not.  |\n",
    "|**Pclass** | This is the class of the passenger's ticket. The possible classes are 1, 2 or 3.  |\n",
    "|**Sex** | This is the gender of the passenger.  0 indicates female, 1 indicates male. |\n",
    "|**Age** | This is the age of the passenger in years. |\n",
    "|**SibSp** | This indicates the number of siblings or spouses (brother, sister, husband, wife) that the passenger had on board with them. |\n",
    "|**Fare** | This is how much the passenger paid for their ticket. |\n",
    "|**Parch** | This is the number of parents or children (mother, father, son, daughter) that the passenger had on board with them.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T15:31:04.230703Z",
     "start_time": "2018-09-17T15:31:04.201756Z"
    }
   },
   "source": [
    "Split the data into <span style=\"color:red\"> **features** </span> and <span style=\"color:red\"> **target information**</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:45:11.134332Z",
     "start_time": "2018-10-17T10:45:11.130407Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df[['Pclass','Age','SibSp','Parch', 'Sex']]\n",
    "y = df[['Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing data by filling in the blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:45:12.329305Z",
     "start_time": "2018-10-17T10:45:12.325120Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(_______ , _______, random_state=2, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to import the model from sklearn.  Googling sklearn Decision Tree gives you this link:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "We can then import the Decision Tree Classifier from this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:45:13.745448Z",
     "start_time": "2018-10-17T10:45:13.743156Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the model we start by calling a Decision Tree classifier.  Then we fit the model to the X_train and y_train data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:51:44.732064Z",
     "start_time": "2018-10-17T10:51:44.716916Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(______ , _______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have trained the model, try making predictions using the features from the test data.  Store this as y_pred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(___input_the_features_from_your_test_data_here___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of your classifier using sklearn's **accuracy_score** function.  It takes the 'truthful' outcomes as the first argument and the predictions as the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:34:08.941155Z",
     "start_time": "2018-10-17T10:34:08.938544Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:34:09.675133Z",
     "start_time": "2018-10-17T10:34:09.670941Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test , y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTENSION TASK:** How does our model compare to someone who just predicted that everyone dies or everyone survives?  (Try counting how many people survived/died in the test data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier <span style=\"color:red\"> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using the same data from the Titanic example in the Decision Tree Classifier section but this time, try using the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:37:12.206577Z",
     "start_time": "2018-10-18T15:37:12.199827Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into features and targets (X and y data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split this into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Random Forest Classifier from the appropriate package:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _____ import ______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a model and then train it by using the .fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T16:20:18.786312Z",
     "start_time": "2018-09-17T16:20:18.782718Z"
    }
   },
   "source": [
    "Test the accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T17:53:46.330264Z",
     "start_time": "2018-09-17T17:53:46.327691Z"
    }
   },
   "source": [
    "# One-hot encoding <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:53:16.299156Z",
     "start_time": "2018-10-17T10:53:16.275027Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('CountryInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:53:16.713275Z",
     "start_time": "2018-10-17T10:53:16.704140Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try one-hot encoding this information to produce another table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to the 'Country' column?  What happens to the 'Revenue' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poor Quality Data Task  <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below imports all tables on the wikipedia page about the Global Peace Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:24:50.236547Z",
     "start_time": "2018-10-12T11:24:49.487292Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Global_Peace_Index#Global_Peace_Index_rankings'\n",
    "dfs = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the second table on this web page, which is referenced with index [1] (because Python counts from zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:24:51.524697Z",
     "start_time": "2018-10-12T11:24:51.521979Z"
    }
   },
   "outputs": [],
   "source": [
    "df = dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T12:56:27.853899Z",
     "start_time": "2018-09-18T12:56:27.850023Z"
    }
   },
   "source": [
    "We need to tidy this code.\n",
    "\n",
    "*Note:*  The steps below will remove unnecessary columns (ranking columns) and will re-assign the 'index' and the 'header'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:24:58.428094Z",
     "start_time": "2018-10-12T11:24:58.420447Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_remove = [i for i in df.loc[0] if 'rank' in i]        # For the purpose of this task we do not want column information about 'rank'\n",
    "new_columns = [i.split('[')[0] for i in df.loc[0] if 'score' in i]       # We do not want the additional references that appear in each column\n",
    "df.columns = df.loc[0]       # Re-assign the columns using the information in the first row\n",
    "df = df.drop(0)        # Get rid of the row that has just been 'copied' into the header \n",
    "df = df.drop(columns=columns_to_remove)        # Remove the columns identified in 'columns_to_remove'\n",
    "df = df.set_index('Country')        # Set the 'Country' column as the index\n",
    "df.columns = new_columns       # Re-assign the column titles without the additional references (listed in the 'new_columns' list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our table has lots of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:26:22.339038Z",
     "start_time": "2018-10-12T11:26:22.335658Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the top 5 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:26:33.659797Z",
     "start_time": "2018-10-12T11:26:33.644096Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below line of code shows us all rows in the dataframe where any entry is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:25:35.058536Z",
     "start_time": "2018-10-12T11:25:35.031128Z"
    }
   },
   "outputs": [],
   "source": [
    "df[pd.isnull(df).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either drop these rows using the dropna method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:25:38.496280Z",
     "start_time": "2018-10-12T11:25:38.492479Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_nulls = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves fewer entries in our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:25:59.749212Z",
     "start_time": "2018-10-12T11:25:59.745772Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(drop_nulls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can replace the Nulls with a value of our choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:26:45.989776Z",
     "start_time": "2018-10-12T11:26:45.984978Z"
    }
   },
   "outputs": [],
   "source": [
    "replace_nulls = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below line of code shows all the rows that contain a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:50:18.029492Z",
     "start_time": "2018-10-12T11:50:18.000713Z"
    }
   },
   "outputs": [],
   "source": [
    "replace_nulls[(replace_nulls.T == 0).any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another table with information on the average and highest attendances at each of the World Cups from 1930 to date.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:50:35.867600Z",
     "start_time": "2018-10-12T11:50:35.298631Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/FIFA_World_Cup'        ## This is the webpage we are importing the table from\n",
    "df = pd.read_html(url, header=0)[2]          ## We are importing the third table \n",
    "df = df.drop([0,22])            ## Remove two unhelpful rows\n",
    "df = df.set_index('Year')          ## Set the 'Year' column as the index \n",
    "df['Highest attendances †'] = df['Highest attendances †'].apply(lambda x: float(x.split('[')[0].replace(',','')))       ##  Remove the square bracket reference\n",
    "df.columns = ['Hosts', 'Venues/Cities', 'Totalattendance', 'Matches',         \n",
    "       'Tournament Avg. attendance', 'Highest attendance', 'Stadium of Highest Attendance', 'Score/Match']        ## Change the column names\n",
    "df['Score/Match'] = df['Score/Match'].apply(lambda x: x.replace(', ',' (')+')')         ## Tidy one of the columns \n",
    "df.set_value('1934', 'Tournament Avg. attendance', 100000000)           ## Create one 'bogus' entry in the table \n",
    "df.set_value('2006', 'Highest attendance', None)          ## Create one Null entry in the table  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T13:36:03.834210Z",
     "start_time": "2018-09-18T13:36:03.819432Z"
    }
   },
   "source": [
    "Try removing any rows with missing data.  Try replacing any missing data with a value of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_nulls = _________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nulls = _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION** \n",
    "Are there any records that surprise you in 'Tournament Avg. attendance'?  Which record surprises you and why?  What could you do with this record?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM  <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a series of ingredients lists for Cupcakes, Muffins and Scones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T14:52:58.390938Z",
     "start_time": "2018-09-24T14:52:58.384141Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('baking.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T14:53:11.943789Z",
     "start_time": "2018-09-24T14:53:11.932683Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[data['Type'].isin(['Muffin','Cupcake'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T16:22:29.060940Z",
     "start_time": "2018-09-17T16:22:29.056550Z"
    }
   },
   "source": [
    "Based on the ingredients we hope to be able to predict whether a recipe is for Cupcakes or Muffins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your X and y data, then split this into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:02:46.831682Z",
     "start_time": "2018-09-24T15:02:46.827836Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:45.623967Z",
     "start_time": "2018-09-24T15:10:45.621328Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data['Type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:45.980219Z",
     "start_time": "2018-09-24T15:10:45.977330Z"
    }
   },
   "outputs": [],
   "source": [
    "y_example = data['Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to convert your 'y' data into 1s and 0s.  Firstly, convert your y data into a list.  Then try converting each element in your list using a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:46.490483Z",
     "start_time": "2018-09-24T15:10:46.487583Z"
    }
   },
   "outputs": [],
   "source": [
    "conversion_dictionary = {'Cupcake': 1,\n",
    "                         'Muffin': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:46.914427Z",
     "start_time": "2018-09-24T15:10:46.912083Z"
    }
   },
   "outputs": [],
   "source": [
    "y = [conversion_dictionary[whatever] for whatever in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:48.309533Z",
     "start_time": "2018-09-24T15:10:48.305279Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:13:46.785727Z",
     "start_time": "2018-09-24T15:13:46.781814Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the appropriate SVC package:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T16:28:04.619669Z",
     "start_time": "2018-09-17T16:28:04.616865Z"
    }
   },
   "outputs": [],
   "source": [
    "from _____ import ______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate your model, then train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using your model and save them as y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did your model perform?  Do you have any concerns about the model you have built?  How could you improve your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN  <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKLearn has some inbuilt datasets, such as the 'iris' dataset (a famous dataset about flowers).  You can import these datasets using the 'load' functions created for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:05.150398Z",
     "start_time": "2018-10-17T14:04:05.009456Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:05.720866Z",
     "start_time": "2018-10-17T14:04:05.687760Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(load_iris()['data']), pd.DataFrame(load_iris()['target'])], axis=1)\n",
    "df.columns = load_iris()['feature_names'] + ['species']\n",
    "\n",
    "flower_dict = {0: 'setosa',\n",
    "              1: 'versicolor',\n",
    "              2: 'virginica'\n",
    "              }\n",
    "\n",
    "df['species'] = df['species'].apply(lambda x: flower_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:07.027153Z",
     "start_time": "2018-10-17T14:04:07.014896Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![iris](iris.png \"iris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sepal](sepal_petal.jpg \"sepal_petal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only visualize data in 3 dimensions, so here are some plots of the data in 3 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:19.719773Z",
     "start_time": "2018-10-17T14:04:18.653113Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:20.337989Z",
     "start_time": "2018-10-17T14:04:20.335516Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:15:15.277637Z",
     "start_time": "2018-10-17T14:15:15.273246Z"
    }
   },
   "outputs": [],
   "source": [
    "set(df['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:05:17.044515Z",
     "start_time": "2018-10-17T14:05:17.041554Z"
    }
   },
   "outputs": [],
   "source": [
    "color_map = {'setosa': 'g',\n",
    "             'versicolor': 'r', \n",
    "             'virginica': 'b'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs below show three different features (out of the four available) plotted against one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:05:22.285014Z",
     "start_time": "2018-10-17T14:05:17.547434Z"
    }
   },
   "outputs": [],
   "source": [
    "for combo in itertools.combinations(df.columns[:-1], 3):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for species in df['species']:\n",
    "        temp = df[df['species']==species]\n",
    "        plt.scatter(temp[combo[0]], temp[combo[1]], temp[combo[2]], color=color_map[species])\n",
    "        ax.set_xlabel(combo[0])\n",
    "        ax.set_ylabel(combo[1])\n",
    "        ax.set_zlabel(combo[2])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the four dimensions to classfiy the datapoints.  Try splitting your data into **features** and **targets** before splitting into **training** and **testing** data.  You can then build a KNeighbours model to predict each flower type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T15:07:57.327605Z",
     "start_time": "2018-10-12T15:07:57.324858Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression  <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a dataset of cars.  Each car has information about its features including the 'miles per gallon' that the car can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T17:10:16.365063Z",
     "start_time": "2018-10-12T17:10:15.349389Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data-original', delim_whitespace=True, header=None)\n",
    "data.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name']\n",
    "data['origin'] = data['origin'].apply(lambda x: {1: 'American',\n",
    "                                                 2: 'European',\n",
    "                                                 3: 'Asian/Other'}[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T17:10:58.430045Z",
     "start_time": "2018-10-12T17:10:58.414697Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**\n",
    "\n",
    "Can you build a linear regression model to predict the 'miles per gallon' given the features provided to you?  How will you measure the performance of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a dataset feature movie reviews from IMDB and their general sentiment.  'Polarity' represents either a good review (1) or a bad review (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:31.787659Z",
     "start_time": "2018-10-18T12:07:31.785261Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:34.754903Z",
     "start_time": "2018-10-18T12:07:32.361071Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import requests\n",
    "url = \"https://raw.githubusercontent.com/SrinidhiRaghavan/AI-Sentiment-Analysis-on-IMDB-Dataset/master/imdb_tr.csv\"\n",
    "s = requests.get(url).text\n",
    "df = pd.read_csv(io.StringIO(s))\n",
    "df = df.set_index('row_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:34.765988Z",
     "start_time": "2018-10-18T12:07:34.757155Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:48:39.536044Z",
     "start_time": "2018-10-18T15:48:39.532702Z"
    }
   },
   "source": [
    "Try building a model that predicts whether a review is good or bad by converting the text into a vector, before passing it through a model that you think will be suitable for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T15:28:27.976812Z",
     "start_time": "2018-10-12T15:28:27.972501Z"
    }
   },
   "source": [
    "First, lets identify our X and y data, then create training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:35.747976Z",
     "start_time": "2018-10-18T12:07:35.745038Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:35.973676Z",
     "start_time": "2018-10-18T12:07:35.966665Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now create a vectorizer that transforms your text into a vector.  To improve the performance of your model you will need to tweak the parameters of your vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:42:31.222664Z",
     "start_time": "2018-10-18T15:42:30.176297Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:49:16.348174Z",
     "start_time": "2018-10-18T15:49:16.344761Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,1), \n",
    "                     max_features=1000,\n",
    "                    stop_words='english',\n",
    "                    max_df=1,\n",
    "                    min_df=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to fit the vectorizer on the corpus of texts in our training data.  We can then transform our training and testing data in a series of vectors to form a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have taught the vectorizer all of the words that it needs to pay attention to (from the training data) we can transform each individual text into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:22:29.104041Z",
     "start_time": "2018-10-18T12:21:12.840538Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_vec = cv.transform(X_train)\n",
    "X_test_vec = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **X_train_vec** and **X_test_vec** information is now 'consumable' by a model.  We can use X_train_vec and the target (y_train) to create our model.  We can then make predictions with X_test_vec and compare them to y_test.  Try different models, different model parameters and different vectorizer parameters to see what performance you achieve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:53:58.055749Z",
     "start_time": "2018-10-18T15:53:58.053216Z"
    }
   },
   "outputs": [],
   "source": [
    "from ___________ import ____________\n",
    "clf = ______________(tweaked_parameter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(_____, ______)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Databases for Projects/Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting whether IMDB movie reviews are positive or negative (text classification task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:15:05.482484Z",
     "start_time": "2018-10-22T08:14:58.055714Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    " \n",
    "url=\"https://raw.githubusercontent.com/SrinidhiRaghavan/AI-Sentiment-Analysis-on-IMDB-Dataset/master/imdb_tr.csv\"\n",
    "s=requests.get(url).text\n",
    " \n",
    "df=pd.read_csv(io.StringIO(s))\n",
    "df = df.set_index('row_Number')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting ‘mpg’ for old cars (regression task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:15:07.265837Z",
     "start_time": "2018-10-22T08:15:06.311121Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data', delim_whitespace=True, header=None)\n",
    "df.columns = ['mpg','cylinders','displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that ‘origin’ represents where the car is made.  1 represents America, 2 represents Europe and 3 represents Asia/other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes Dataset (classification task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:15:09.116860Z",
     "start_time": "2018-10-22T08:15:08.732230Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "df = pd.read_csv('https://gist.githubusercontent.com/chaityacshah/899a95deaf8b1930003ae93944fd17d7/raw/3d35de839da708595a444187e9f13237b51a2cbe/pima-indians-diabetes.csv')\n",
    "df.rename(index=str, columns={\"9. Class variable (0 or 1)\": \"9. Diabetes Yes/No\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:15:09.281177Z",
     "start_time": "2018-10-22T08:15:09.276118Z"
    }
   },
   "source": [
    "Please note that the diabetes pedigree function is a function that represents how likely a patient is to get the disease using information from their ancestry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the ‘cultivar’ (source) of a wine (classification task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T08:16:11.642643Z",
     "start_time": "2018-10-22T08:16:08.329788Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "info = load_wine()\n",
    "X = pd.DataFrame(info['data'])\n",
    "X.columns = info['feature_names']\n",
    "y = info['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Dataset (classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download CSV from tab in top right corner:  https://www.openml.org/d/13\n",
    "Save the CSV file as 'dataset_13_breast-cancer.csv' in the same location as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset_13_breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newsgroup dataset (classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try predicting which of the 20 newsgroups the ‘post’ belongs to.  Be careful, as you will need to ‘strip’ some of the information from the model so there isn’t any “bleeding” of information between your training and testing sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "info = fetch_20newsgroups()\n",
    "X = pd.DataFrame(info[‘data’])\n",
    "y = pd.DataFrame(info[‘target’])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston House Prices (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    " \n",
    "info = load_boston()\n",
    " \n",
    "X = pd.DataFrame(info[‘data’])\n",
    "X.columns = info[‘feature_names’]\n",
    "y = pd.DataFrame(info[‘target’])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "194px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
