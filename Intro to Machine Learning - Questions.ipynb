{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split  <span style=\"color:red\"> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, lets import pandas so we can handle tables effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:35.144800Z",
     "start_time": "2018-10-17T09:31:35.142179Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Golfer John likes to play golf, but only in certain conditions.  Below is a table of data relating to the different conditions in which Golfer John did and did not play golf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:35.544724Z",
     "start_time": "2018-10-17T09:31:35.537116Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('GolferJohn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the top five rows of this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:35.920621Z",
     "start_time": "2018-10-17T09:31:35.908883Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the table above into X data (features) and y data (in our case, whether or not Golfer John played golf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:36.335773Z",
     "start_time": "2018-10-17T09:31:36.324302Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data[['Weather', 'Temperature', 'Humidity', 'Windy', 'Ice cream available']]        ## Features:  Information relating to whether Golfer John played or not\n",
    "y = data[['Play golf?']]                                                                ## Target:  Whether or not Golfer John played golf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the train_test_split function from the appropriate package:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:36.850603Z",
     "start_time": "2018-10-17T09:31:36.847955Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the train_test_split function, split your data into X_train, X_test, y_train and y_test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:37.499155Z",
     "start_time": "2018-10-17T09:31:37.488117Z"
    }
   },
   "outputs": [],
   "source": [
    "##Â Put your code in this cell to split the data into the appropriate training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing the same train-test split but this time specifying that the test data is 30% of the total data available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T09:31:38.357012Z",
     "start_time": "2018-10-17T09:31:38.352098Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing another train-test split, but this time specifying that the data is shuffled before being split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the benefit of using the 'random_state' parameter?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:32:01.171176Z",
     "start_time": "2018-10-18T15:32:01.070687Z"
    }
   },
   "source": [
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTENSION TASK:**  What does the train-test split's 'stratify' condition do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, we can now use this information to develop a Machine Learning model to predict whether or not Golfer John played in certain weather conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier <span style=\"color:red\"> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below data is for passengers on the Titanic.  We can use Machine Learning to train a model and predict whether a passenger would have survived or not on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T17:08:04.643542Z",
     "start_time": "2018-10-12T17:08:04.639193Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://titanichistoricalsociety.org/wp-content/uploads/2017/09/titanic_historical_society_homepage_harley_crossley.jpg\", width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data below is a subset of the full data available on Kaggle:  https://www.kaggle.com/c/titanic#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:20:02.592415Z",
     "start_time": "2018-10-17T10:20:02.546753Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_data.csv')\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T16:17:37.660183Z",
     "start_time": "2018-09-17T16:17:37.656990Z"
    }
   },
   "source": [
    "Below is a brief description of each of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Feature** |  **Description**   |\n",
    "|:-----------|------------:|\n",
    "| **Survived**       |        This tells us whether the person survived or not.  |\n",
    "|**Pclass** | This is the class of the passenger's ticket. The possible classes are 1, 2 or 3.  |\n",
    "|**Sex** | This is the gender of the passenger.  0 indicates female, 1 indicates male. |\n",
    "|**Age** | This is the age of the passenger in years. |\n",
    "|**SibSp** | This indicates the number of siblings or spouses (brother, sister, husband, wife) that the passenger had on board with them. |\n",
    "|**Fare** | This is how much the passenger paid for their ticket. |\n",
    "|**Parch** | This is the number of parents or children (mother, father, son, daughter) that the passenger had on board with them.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T15:31:04.230703Z",
     "start_time": "2018-09-17T15:31:04.201756Z"
    }
   },
   "source": [
    "Split the data into <span style=\"color:red\"> **features** </span> and <span style=\"color:red\"> **target information**</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:45:11.134332Z",
     "start_time": "2018-10-17T10:45:11.130407Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df[['Pclass','Age','SibSp','Parch', 'Sex']]\n",
    "y = df[['Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing data by filling in the blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:45:12.329305Z",
     "start_time": "2018-10-17T10:45:12.325120Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(_______ , _______, random_state=2, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to import the model from sklearn.  Googling sklearn Decision Tree gives you this link:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "We can then import the Decision Tree Classifier from this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:45:13.745448Z",
     "start_time": "2018-10-17T10:45:13.743156Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the model we start by calling a Decision Tree classifier.  Then we fit the model to the X_train and y_train data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:51:44.732064Z",
     "start_time": "2018-10-17T10:51:44.716916Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(______ , _______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have trained the model, try making predictions using the features from the test data.  Store this as y_pred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(___input_the_features_from_your_test_data_here___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of your classifier using sklearn's **accuracy_score** function.  It takes the 'truthful' outcomes as the first argument and the predictions as the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:34:08.941155Z",
     "start_time": "2018-10-17T10:34:08.938544Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:34:09.675133Z",
     "start_time": "2018-10-17T10:34:09.670941Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test , y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTENSION TASK:** How does our model compare to someone who just predicted that everyone dies or everyone survives?  (Try counting how many people survived/died in the test data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Random Forest Classifier <span style=\"color:red\"> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using the same data from the Titanic example in the Decision Tree Classifier section but this time, try using the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:37:12.206577Z",
     "start_time": "2018-10-18T15:37:12.199827Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into features and targets (X and y data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split this into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Random Forest Classifier from the appropriate package:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _____ import ______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a model and then train it by using the .fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T16:20:18.786312Z",
     "start_time": "2018-09-17T16:20:18.782718Z"
    }
   },
   "source": [
    "Test the accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T17:53:46.330264Z",
     "start_time": "2018-09-17T17:53:46.327691Z"
    }
   },
   "source": [
    "# One-hot encoding <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:53:16.299156Z",
     "start_time": "2018-10-17T10:53:16.275027Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('CountryInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T10:53:16.713275Z",
     "start_time": "2018-10-17T10:53:16.704140Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try one-hot encoding this information to produce another table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to the 'Country' column?  What happens to the 'Revenue' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poor Quality Data Task  <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below imports all tables on the wikipedia page about the Global Peace Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:24:50.236547Z",
     "start_time": "2018-10-12T11:24:49.487292Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Global_Peace_Index#Global_Peace_Index_rankings'\n",
    "dfs = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the second table on this web page, which is referenced with index [1] (because Python counts from zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:24:51.524697Z",
     "start_time": "2018-10-12T11:24:51.521979Z"
    }
   },
   "outputs": [],
   "source": [
    "df = dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T12:56:27.853899Z",
     "start_time": "2018-09-18T12:56:27.850023Z"
    }
   },
   "source": [
    "We need to tidy this code.\n",
    "\n",
    "*Note:*  The steps below will remove unnecessary columns (ranking columns) and will re-assign the 'index' and the 'header'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:24:58.428094Z",
     "start_time": "2018-10-12T11:24:58.420447Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_remove = [i for i in df.loc[0] if 'rank' in i]        # For the purpose of this task we do not want column information about 'rank'\n",
    "new_columns = [i.split('[')[0] for i in df.loc[0] if 'score' in i]       # We do not want the additional references that appear in each column\n",
    "df.columns = df.loc[0]       # Re-assign the columns using the information in the first row\n",
    "df = df.drop(0)        # Get rid of the row that has just been 'copied' into the header \n",
    "df = df.drop(columns=columns_to_remove)        # Remove the columns identified in 'columns_to_remove'\n",
    "df = df.set_index('Country')        # Set the 'Country' column as the index\n",
    "df.columns = new_columns       # Re-assign the column titles without the additional references (listed in the 'new_columns' list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our table has lots of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:26:22.339038Z",
     "start_time": "2018-10-12T11:26:22.335658Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the top 5 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:26:33.659797Z",
     "start_time": "2018-10-12T11:26:33.644096Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below line of code shows us all rows in the dataframe where any entry is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:25:35.058536Z",
     "start_time": "2018-10-12T11:25:35.031128Z"
    }
   },
   "outputs": [],
   "source": [
    "df[pd.isnull(df).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either drop these rows using the dropna method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:25:38.496280Z",
     "start_time": "2018-10-12T11:25:38.492479Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_nulls = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves fewer entries in our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:25:59.749212Z",
     "start_time": "2018-10-12T11:25:59.745772Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(drop_nulls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can replace the Nulls with a value of our choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:26:45.989776Z",
     "start_time": "2018-10-12T11:26:45.984978Z"
    }
   },
   "outputs": [],
   "source": [
    "replace_nulls = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below line of code shows all the rows that contain a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:50:18.029492Z",
     "start_time": "2018-10-12T11:50:18.000713Z"
    }
   },
   "outputs": [],
   "source": [
    "replace_nulls[(replace_nulls.T == 0).any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another table with information on the average and highest attendances at each of the World Cups from 1930 to date.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T11:50:35.867600Z",
     "start_time": "2018-10-12T11:50:35.298631Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/FIFA_World_Cup'        ## This is the webpage we are importing the table from\n",
    "df = pd.read_html(url, header=0)[2]          ## We are importing the third table \n",
    "df = df.drop([0,22])            ## Remove two unhelpful rows\n",
    "df = df.set_index('Year')          ## Set the 'Year' column as the index \n",
    "df['Highest attendances â '] = df['Highest attendances â '].apply(lambda x: float(x.split('[')[0].replace(',','')))       ##  Remove the square bracket reference\n",
    "df.columns = ['Hosts', 'Venues/Cities', 'Totalattendance', 'Matches',         \n",
    "       'Tournament Avg. attendance', 'Highest attendance', 'Stadium of Highest Attendance', 'Score/Match']        ## Change the column names\n",
    "df['Score/Match'] = df['Score/Match'].apply(lambda x: x.replace(', ',' (')+')')         ## Tidy one of the columns \n",
    "df.set_value('1934', 'Tournament Avg. attendance', 100000000)           ## Create one 'bogus' entry in the table \n",
    "df.set_value('2006', 'Highest attendance', None)          ## Create one Null entry in the table  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T13:36:03.834210Z",
     "start_time": "2018-09-18T13:36:03.819432Z"
    }
   },
   "source": [
    "Try removing any rows with missing data.  Try replacing any missing data with a value of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_nulls = _________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nulls = _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION** \n",
    "Are there any records that surprise you in 'Tournament Avg. attendance'?  Which record surprises you and why?  What could you do with this record?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM  <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a series of ingredients lists for Cupcakes, Muffins and Scones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T14:52:58.390938Z",
     "start_time": "2018-09-24T14:52:58.384141Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('baking.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T14:53:11.943789Z",
     "start_time": "2018-09-24T14:53:11.932683Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[data['Type'].isin(['Muffin','Cupcake'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T16:22:29.060940Z",
     "start_time": "2018-09-17T16:22:29.056550Z"
    }
   },
   "source": [
    "Based on the ingredients we hope to be able to predict whether a recipe is for Cupcakes or Muffins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your X and y data, then split this into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:02:46.831682Z",
     "start_time": "2018-09-24T15:02:46.827836Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:45.623967Z",
     "start_time": "2018-09-24T15:10:45.621328Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data['Type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:45.980219Z",
     "start_time": "2018-09-24T15:10:45.977330Z"
    }
   },
   "outputs": [],
   "source": [
    "y_example = data['Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to convert your 'y' data into 1s and 0s.  Firstly, convert your y data into a list.  Then try converting each element in your list using a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:46.490483Z",
     "start_time": "2018-09-24T15:10:46.487583Z"
    }
   },
   "outputs": [],
   "source": [
    "conversion_dictionary = {'Cupcake': 1,\n",
    "                         'Muffin': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:46.914427Z",
     "start_time": "2018-09-24T15:10:46.912083Z"
    }
   },
   "outputs": [],
   "source": [
    "y = [conversion_dictionary[whatever] for whatever in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:10:48.309533Z",
     "start_time": "2018-09-24T15:10:48.305279Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:13:46.785727Z",
     "start_time": "2018-09-24T15:13:46.781814Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the appropriate SVC package:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T16:28:04.619669Z",
     "start_time": "2018-09-17T16:28:04.616865Z"
    }
   },
   "outputs": [],
   "source": [
    "from _____ import ______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate your model, then train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using your model and save them as y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did your model perform?  Do you have any concerns about the model you have built?  How could you improve your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â KNN  <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKLearn has some inbuilt datasets, such as the 'iris' dataset (a famous dataset about flowers).  You can import these datasets using the 'load' functions created for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:05.150398Z",
     "start_time": "2018-10-17T14:04:05.009456Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:05.720866Z",
     "start_time": "2018-10-17T14:04:05.687760Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(load_iris()['data']), pd.DataFrame(load_iris()['target'])], axis=1)\n",
    "df.columns = load_iris()['feature_names'] + ['species']\n",
    "\n",
    "flower_dict = {0: 'setosa',\n",
    "              1: 'versicolor',\n",
    "              2: 'virginica'\n",
    "              }\n",
    "\n",
    "df['species'] = df['species'].apply(lambda x: flower_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:07.027153Z",
     "start_time": "2018-10-17T14:04:07.014896Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![iris](iris.png \"iris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sepal](sepal_petal.jpg \"sepal_petal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only visualize data in 3 dimensions, so here are some plots of the data in 3 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:19.719773Z",
     "start_time": "2018-10-17T14:04:18.653113Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:04:20.337989Z",
     "start_time": "2018-10-17T14:04:20.335516Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:15:15.277637Z",
     "start_time": "2018-10-17T14:15:15.273246Z"
    }
   },
   "outputs": [],
   "source": [
    "set(df['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:05:17.044515Z",
     "start_time": "2018-10-17T14:05:17.041554Z"
    }
   },
   "outputs": [],
   "source": [
    "color_map = {'setosa': 'g',\n",
    "             'versicolor': 'r', \n",
    "             'virginica': 'b'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs below show three different features (out of the four available) plotted against one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T14:05:22.285014Z",
     "start_time": "2018-10-17T14:05:17.547434Z"
    }
   },
   "outputs": [],
   "source": [
    "for combo in itertools.combinations(df.columns[:-1], 3):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for species in df['species']:\n",
    "        temp = df[df['species']==species]\n",
    "        plt.scatter(temp[combo[0]], temp[combo[1]], temp[combo[2]], color=color_map[species])\n",
    "        ax.set_xlabel(combo[0])\n",
    "        ax.set_ylabel(combo[1])\n",
    "        ax.set_zlabel(combo[2])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the four dimensions to classfiy the datapoints.  Try splitting your data into **features** and **targets** before splitting into **training** and **testing** data.  You can then build a KNeighbours model to predict each flower type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T15:07:57.327605Z",
     "start_time": "2018-10-12T15:07:57.324858Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Linear Regression  <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a dataset of cars.  Each car has information about its features including the 'miles per gallon' that the car can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T17:10:16.365063Z",
     "start_time": "2018-10-12T17:10:15.349389Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data-original', delim_whitespace=True, header=None)\n",
    "data.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name']\n",
    "data['origin'] = data['origin'].apply(lambda x: {1: 'American',\n",
    "                                                 2: 'European',\n",
    "                                                 3: 'Asian/Other'}[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T17:10:58.430045Z",
     "start_time": "2018-10-12T17:10:58.414697Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**\n",
    "\n",
    "Can you build a linear regression model to predict the 'miles per gallon' given the features provided to you?  How will you measure the performance of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing <span style='color:red'> TASK <span/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a dataset feature movie reviews from IMDB and their general sentiment.  'Polarity' represents either a good review (1) or a bad review (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:31.787659Z",
     "start_time": "2018-10-18T12:07:31.785261Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:34.754903Z",
     "start_time": "2018-10-18T12:07:32.361071Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import requests\n",
    "url = \"https://raw.githubusercontent.com/SrinidhiRaghavan/AI-Sentiment-Analysis-on-IMDB-Dataset/master/imdb_tr.csv\"\n",
    "s = requests.get(url).text\n",
    "df = pd.read_csv(io.StringIO(s))\n",
    "df = df.set_index('row_Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:34.765988Z",
     "start_time": "2018-10-18T12:07:34.757155Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:48:39.536044Z",
     "start_time": "2018-10-18T15:48:39.532702Z"
    }
   },
   "source": [
    "Try building a model that predicts whether a review is good or bad by converting the text into a vector, before passing it through a model that you think will be suitable for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-12T15:28:27.976812Z",
     "start_time": "2018-10-12T15:28:27.972501Z"
    }
   },
   "source": [
    "First, lets identify our X and y data, then create training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:35.747976Z",
     "start_time": "2018-10-18T12:07:35.745038Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:07:35.973676Z",
     "start_time": "2018-10-18T12:07:35.966665Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now create a vectorizer that transforms your text into a vector.  To improve the performance of your model you will need to tweak the parameters of your vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:42:31.222664Z",
     "start_time": "2018-10-18T15:42:30.176297Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:49:16.348174Z",
     "start_time": "2018-10-18T15:49:16.344761Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,1), \n",
    "                     max_features=1000,\n",
    "                    stop_words='english',\n",
    "                    max_df=1,\n",
    "                    min_df=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to fit the vectorizer on the corpus of texts in our training data.  We can then transform our training and testing data in a series of vectors to form a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have taught the vectorizer all of the words that it needs to pay attention to (from the training data) we can transform each individual text into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T12:22:29.104041Z",
     "start_time": "2018-10-18T12:21:12.840538Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_vec = cv.transform(X_train)\n",
    "X_test_vec = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **X_train_vec** and **X_test_vec** information is now 'consumable' by a model.  We can use X_train_vec and the target (y_train) to create our model.  We can then make predictions with X_test_vec and compare them to y_test.  Try different models, different model parameters and different vectorizer parameters to see what performance you achieve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:53:58.055749Z",
     "start_time": "2018-10-18T15:53:58.053216Z"
    }
   },
   "outputs": [],
   "source": [
    "from ___________ import ____________\n",
    "clf = ______________(tweaked_parameter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(_____, ______)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "194px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
